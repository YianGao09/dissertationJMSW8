{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d722dc91-e45d-4dcf-b014-4e53db40a0d8",
   "metadata": {},
   "source": [
    "### 2011data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be81c71-37d3-495c-9f02-b66f70d7b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('11_populationdensity.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_11populationdensity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108cded4-5d37-497e-b145-003cf693bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('11_household.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_11household.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567e068d-6215-48c1-a2f1-75379af82ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('11_fertility.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_11fertility.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1e8354-457a-4251-ad21-62802785be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('11_level4.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_11level4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10065eae-7fd0-4e79-918a-c3c182892715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('11_unemployment.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_11unemployment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd4c62a-e1f1-4ab0-a5c2-bf1aeda4c62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('11_disability.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_11disability.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22704b-8e08-4c44-8a06-102ecbf4b2f2",
   "metadata": {},
   "source": [
    "### 2021data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea767d9c-0771-4bc1-a525-281f87132ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('21_populationdensity.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_21populationdensity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87fd4920-c46c-4de7-ab48-ef78d83ead52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('21_household.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_21household.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d0ad0e-b594-4c69-a4e3-855102ee75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('21_fertility.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_21fertility.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "091c91d3-fb8b-41ea-ab3a-4f3f5920dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('21_level4.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_21level4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106768d9-c174-40eb-9c87-1bfa1d3a8cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('21_unemployment.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_21unemployment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3930a869-2b73-4bd3-833d-9c1647700e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 'MSOA Code',  'MSOA Name', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',         2002,\n",
      "       ...\n",
      "           'Slight', '2010 Total',    'Fatal.1',  'Serious.1',   'Slight.1',\n",
      "       '2011 Total',    'Fatal.2',  'Serious.2',   'Slight.2', '2012 Total'],\n",
      "      dtype='object', length=207)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个文件，并跳过前两行\n",
    "df1 = pd.read_excel('msoa2011.xltx', skiprows=2)\n",
    "\n",
    "# 读取第二个文件\n",
    "df2 = pd.read_csv('21_disability.csv')\n",
    "\n",
    "# 确认第一个文件的列名\n",
    "print(df1.columns)\n",
    "\n",
    "# 提取第一个文件中的 MSOA Code 列，并删除 NaN 值\n",
    "msoa_codes = df1['MSOA Code'].dropna().unique()\n",
    "\n",
    "# 删除第二个文件中不属于第一个文件的 MSOA Code 的行\n",
    "filtered_df2 = df2[df2['geography code'].isin(msoa_codes)]\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "filtered_df2.to_csv('filtered_21disability.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ffeb0-f58a-4818-92ea-a75913a42c8b",
   "metadata": {},
   "source": [
    "### IDW method in 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d85df30-71c7-49eb-ae44-5b036a75e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新后的CSV文件已保存。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "# 读取CSV文件\n",
    "# Read the CSV file\n",
    "csv_file_path = '2021allecofactor.xlsx'\n",
    "data_2021 = pd.read_excel(csv_file_path)\n",
    "\n",
    "# 读取Shapefile文件\n",
    "# Read the Shapefile\n",
    "shapefile_path = 'MSOA_2011_London_gen_MHW.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# 确保列名匹配\n",
    "# Ensure column names match\n",
    "csv_code_col = 'geography code'\n",
    "shape_code_col = 'MSOA11CD'\n",
    "\n",
    "# 仅保留在shapefile中的MSOA\n",
    "# Retain only MSOA present in the shapefile\n",
    "data_2021 = data_2021[data_2021[csv_code_col].isin(gdf[shape_code_col])]\n",
    "\n",
    "# 查找缺失MSOA\n",
    "# Find missing MSOA\n",
    "missing_msoa = gdf[~gdf[shape_code_col].isin(data_2021[csv_code_col])]\n",
    "\n",
    "# 使用IDW插值填补缺失值\n",
    "# Use IDW interpolation to fill missing values\n",
    "def idw_interpolation(xy_known, values_known, xy_unknown, k=6):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn.fit(xy_known, values_known)\n",
    "    interpolated_values = knn.predict(xy_unknown)\n",
    "    return interpolated_values\n",
    "\n",
    "# 提取已知点和未知点的坐标\n",
    "# Extract coordinates of known and unknown points\n",
    "known_points = gdf[gdf[shape_code_col].isin(data_2021[csv_code_col])].geometry.apply(lambda geom: (geom.centroid.x, geom.centroid.y))\n",
    "known_points = np.array(known_points.tolist())\n",
    "\n",
    "# 初始化缺失数据的DataFrame\n",
    "# Initialize the DataFrame for missing data\n",
    "missing_data_df = pd.DataFrame({csv_code_col: missing_msoa[shape_code_col]})\n",
    "\n",
    "# 定义需要插值的列\n",
    "# Define the columns to interpolate\n",
    "columns_to_interpolate = [\n",
    "    '21disability', '21fertility', '21household',\n",
    "    '21level4', '21populationdensity', '21employment'\n",
    "]\n",
    "\n",
    "# 对每个需要插值的列进行处理\n",
    "# Process each column that needs interpolation\n",
    "for column in columns_to_interpolate:\n",
    "    known_values = data_2021[column]\n",
    "    unknown_points = missing_msoa.geometry.apply(lambda geom: (geom.centroid.x, geom.centroid.y))\n",
    "    unknown_points = np.array(unknown_points.tolist())\n",
    "    interpolated_values = idw_interpolation(known_points, known_values, unknown_points)\n",
    "    missing_data_df[column] = interpolated_values\n",
    "\n",
    "# 复制非数值列的数据\n",
    "# Copy non-numeric columns data\n",
    "missing_data_df['date'] = '2021'\n",
    "missing_data_df['geography'] = missing_msoa['MSOA11NM']\n",
    "missing_data_df['geography code'] = missing_msoa['MSOA11CD']\n",
    "\n",
    "# 将缺失数据添加回原数据\n",
    "# Add missing data back to the original data\n",
    "updated_data_2021 = pd.concat([data_2021, missing_data_df], ignore_index=True)\n",
    "\n",
    "# 保存更新后的CSV文件\n",
    "# Save the updated CSV file\n",
    "updated_data_2021.to_csv('updated_2021allecofactor.csv', index=False)\n",
    "print(\"更新后的CSV文件已保存。\")  # The updated CSV file has been saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b26780-8d81-4c87-8a90-2059b15cacf8",
   "metadata": {},
   "source": [
    "### 对齐2011与2021数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca437170-3147-4cfb-a70c-2ab775797e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched Rows in 2021 Data: Empty DataFrame\n",
      "Columns: [date, geography, geography code, 21disability, 21fertility, 21household, 21level4, 21populationdensity, 21employment]\n",
      "Index: []\n",
      "2021 data has been synchronized with 2011 geography codes and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data_2011 = pd.read_excel('2011allecofactor.xlsx')\n",
    "data_2021 = pd.read_csv('updated_2021allecofactor.csv')\n",
    "\n",
    "# Ensure the 'geography code' in both datasets is treated as a string\n",
    "data_2011['geography code'] = data_2011['geography code'].astype(str)\n",
    "data_2021['geography code'] = data_2021['geography code'].astype(str)\n",
    "\n",
    "# Sort the 2021 data to match the order of the 2011 data using a left merge\n",
    "synchronized_data = pd.merge(data_2011[['geography code']], data_2021, on='geography code', how='left')\n",
    "\n",
    "# Check for any rows from 2021 data that didn't find a match in 2011 data\n",
    "unmatched_rows = data_2021[~data_2021['geography code'].isin(data_2011['geography code'])]\n",
    "print(\"Unmatched Rows in 2021 Data:\", unmatched_rows)\n",
    "\n",
    "# Save the synchronized 2021 data\n",
    "synchronized_data.to_csv('synchronized_2021_data.csv', index=False)\n",
    "print(\"2021 data has been synchronized with 2011 geography codes and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4c7a7-733c-46db-9cba-9d13c8e44b48",
   "metadata": {},
   "source": [
    "### filter house price in London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f33a45f-6133-4a4f-b230-8aa2de796f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel文件的列名:  Index(['Local authority code', 'Local authority name', 'MSOA code',\n",
      "       'MSOA name', 'Year ending Dec 1995', 'Year ending Mar 1996',\n",
      "       'Year ending Jun 1996', 'Year ending Sep 1996', 'Year ending Dec 1996',\n",
      "       'Year ending Mar 1997',\n",
      "       ...\n",
      "       'Year ending Dec 2020', 'Year ending Mar 2021', 'Year ending Jun 2021',\n",
      "       'Year ending Sep 2021', 'Year ending Dec 2021', 'Year ending Mar 2022',\n",
      "       'Year ending Jun 2022', 'Year ending Sep 2022', 'Year ending Dec 2022',\n",
      "       'Year ending Mar 2023'],\n",
      "      dtype='object', length=114)\n",
      "Filtered data has been saved to filtered_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "#筛选所有属于伦敦的mean house price \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 加载shapefile\n",
    "shapefile_path = 'MSOA_2011_London_gen_MHW.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# 从shapefile获取MSOA区域代码\n",
    "msoa_codes = gdf['MSOA11CD'].tolist()\n",
    "\n",
    "# 读取Excel文件\n",
    "final_data_path = 'final.xlsx'\n",
    "df_final = pd.read_excel(final_data_path, sheet_name='meanhouseprice')\n",
    "\n",
    "# 检查Excel文件的列名\n",
    "print(\"Excel文件的列名: \", df_final.columns)\n",
    "\n",
    "# 手动选择 MSOA code 列名\n",
    "msoa_column_name = 'MSOA code'\n",
    "\n",
    "# 筛选出在shapefile中存在的MSOA区域的行\n",
    "filtered_df = df_final[df_final[msoa_column_name].isin(msoa_codes)]\n",
    "\n",
    "# 保存筛选后的结果到新的Excel文件\n",
    "output_path = 'filtered_final.xlsx'\n",
    "filtered_df.to_excel(output_path, index=False, float_format=\"%.2f\")\n",
    "\n",
    "print(f\"Filtered data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5073df66-dc5c-450b-a77c-2b5d8d3b9463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel文件的列名:  Index(['Local authority code', 'Local authority name', 'MSOA code',\n",
      "       'MSOA name', 'Year ending Dec 1995', 'Year ending Mar 1996',\n",
      "       'Year ending Jun 1996', 'Year ending Sep 1996', 'Year ending Dec 1996',\n",
      "       'Year ending Mar 1997',\n",
      "       ...\n",
      "       'Year ending Dec 2020', 'Year ending Mar 2021', 'Year ending Jun 2021',\n",
      "       'Year ending Sep 2021', 'Year ending Dec 2021', 'Year ending Mar 2022',\n",
      "       'Year ending Jun 2022', 'Year ending Sep 2022', 'Year ending Dec 2022',\n",
      "       'Year ending Mar 2023'],\n",
      "      dtype='object', length=114)\n",
      "Filtered data has been saved to filtered2_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "#筛选属于伦敦的detached house price\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 加载shapefile\n",
    "shapefile_path = 'MSOA_2011_London_gen_MHW.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# 从shapefile获取MSOA区域代码\n",
    "msoa_codes = gdf['MSOA11CD'].tolist()\n",
    "\n",
    "# 读取Excel文件\n",
    "final_data_path = 'final.xlsx'\n",
    "df_final = pd.read_excel(final_data_path, sheet_name='detachedprice')\n",
    "\n",
    "# 检查Excel文件的列名\n",
    "print(\"Excel文件的列名: \", df_final.columns)\n",
    "\n",
    "# 手动选择 MSOA code 列名\n",
    "msoa_column_name = 'MSOA code'\n",
    "\n",
    "# 筛选出在shapefile中存在的MSOA区域的行\n",
    "filtered_df = df_final[df_final[msoa_column_name].isin(msoa_codes)]\n",
    "\n",
    "# 保存筛选后的结果到新的Excel文件\n",
    "output_path = 'filtered2_final.xlsx'\n",
    "filtered_df.to_excel(output_path, index=False, float_format=\"%.2f\")\n",
    "\n",
    "print(f\"Filtered data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "757e61e8-c705-4a49-b32d-daa5d53c9d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel文件的列名:  Index(['Local authority code', 'Local authority name', 'MSOA code',\n",
      "       'MSOA name', 'Year ending Dec 1995', 'Year ending Mar 1996',\n",
      "       'Year ending Jun 1996', 'Year ending Sep 1996', 'Year ending Dec 1996',\n",
      "       'Year ending Mar 1997',\n",
      "       ...\n",
      "       'Year ending Dec 2020', 'Year ending Mar 2021', 'Year ending Jun 2021',\n",
      "       'Year ending Sep 2021', 'Year ending Dec 2021', 'Year ending Mar 2022',\n",
      "       'Year ending Jun 2022', 'Year ending Sep 2022', 'Year ending Dec 2022',\n",
      "       'Year ending Mar 2023'],\n",
      "      dtype='object', length=114)\n",
      "Filtered data has been saved to filtered3_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "#筛选所有属于伦敦的median house price\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 加载shapefile\n",
    "shapefile_path = 'MSOA_2011_London_gen_MHW.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# 从shapefile获取MSOA区域代码\n",
    "msoa_codes = gdf['MSOA11CD'].tolist()\n",
    "\n",
    "# 读取Excel文件\n",
    "final_data_path = 'final.xlsx'\n",
    "df_final = pd.read_excel(final_data_path, sheet_name='Sheet2')\n",
    "\n",
    "# 检查Excel文件的列名\n",
    "print(\"Excel文件的列名: \", df_final.columns)\n",
    "\n",
    "# 手动选择 MSOA code 列名\n",
    "msoa_column_name = 'MSOA code'\n",
    "\n",
    "# 筛选出在shapefile中存在的MSOA区域的行\n",
    "filtered_df = df_final[df_final[msoa_column_name].isin(msoa_codes)]\n",
    "\n",
    "# 保存筛选后的结果到新的Excel文件\n",
    "output_path = 'filtered3_final.xlsx'\n",
    "filtered_df.to_excel(output_path, index=False, float_format=\"%.2f\")\n",
    "\n",
    "print(f\"Filtered data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b85baa-e2ba-48de-a991-8b9f2537b9b1",
   "metadata": {},
   "source": [
    "###对齐平均房价与社会经济指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d033bad9-4af4-4730-86f7-9667a57026a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已过滤并按照2011年MSOA code顺序排序完成。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取2011和过滤后的最终数据\n",
    "df_2011 = pd.read_excel('2011allecofactor.xlsx')\n",
    "df_filtered_final = pd.read_excel('filtered_final.xlsx')\n",
    "\n",
    "# 获取2011数据中的MSOA code顺序\n",
    "msoa_codes_2011 = df_2011['geography code'].tolist()\n",
    "\n",
    "# 根据2011的MSOA code顺序过滤和排序filtered_final中的数据\n",
    "df_filtered_sorted = df_filtered_final[df_filtered_final['MSOA code'].isin(msoa_codes_2011)]\n",
    "df_filtered_sorted = df_filtered_sorted.set_index('MSOA code').loc[msoa_codes_2011].reset_index()\n",
    "\n",
    "# 保存为新的Excel文件\n",
    "df_filtered_sorted.to_excel('sorted_filtered_final.xlsx', index=False)\n",
    "\n",
    "print(\"数据已过滤并按照2011年MSOA code顺序排序完成。\")\n",
    "##之后自己把2011，2021和对齐后的数据合并在一个叫finaldata的csv文件里\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ebbc0-b4bb-49bd-910e-615468d5e9bb",
   "metadata": {},
   "source": [
    "### 填补median house price的缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebdff438-a0b9-468d-835e-b7e15772bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94582/198409.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[col] = data[col].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的数据已保存到 filled_filtered3_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 指定数据文件的路径（当前目录中）\n",
    "file_path = 'filtered3_final.xlsx'\n",
    "output_file_path = 'filled_filtered3_final.xlsx'\n",
    "\n",
    "# 加载Excel数据文件\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 替换\":\"为NaN，以便进行缺失值处理\n",
    "data.replace(':', np.nan, inplace=True)\n",
    "\n",
    "# 转换数据类型为数值型，以便进行计算和填充\n",
    "data.iloc[:, 4:] = data.iloc[:, 4:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 填充所有年份的中位数价格，只填充缺失值\n",
    "median_price_columns = data.columns[4:]  # 从第5列开始到最后一列\n",
    "for col in median_price_columns:\n",
    "    data[col] = data[col].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# 保存处理后的数据到新的Excel文件\n",
    "data.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"处理后的数据已保存到 {output_file_path}\")\n",
    "\n",
    "#之后把填充好的median house price粘贴到finaldata这个初始数据表中\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1298a-99cb-42ed-93f5-903e14fb0e05",
   "metadata": {},
   "source": [
    "这个填补方法使用了向前填充（forward fill）和向后填充（backward fill）两种策略。具体来说，这种方法是先用前一个有效值填补缺失值，如果前面没有有效值，再用后一个有效值填补剩余的缺失值。这种方法确保所有缺失值都被填补，但不会改变已有的非缺失值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f1943-a11f-4649-9d1a-db1b318440ef",
   "metadata": {},
   "source": [
    "### 给mean house price 取log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c014401-5aeb-48ca-96b5-7f429602df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([           'MSOA code', 'Local authority code', 'Local authority name',\n",
      "                  'MSOA name',                   2000,                   2001,\n",
      "                         2002,                   2003,                   2004,\n",
      "                         2005,                   2006,                   2007,\n",
      "                         2008,                   2009,                   2010,\n",
      "                         2011,                   2012,                   2013,\n",
      "                         2014,                   2015,                   2016,\n",
      "                         2017,                   2018,                   2019,\n",
      "                         2020,                   2021,          'Unnamed: 26',\n",
      "               '11disability',          '11fertility',          '11household',\n",
      "                   '11level4',  '11populationdensity',         '11employment',\n",
      "                'Unnamed: 33',         '21disability',          '21fertility',\n",
      "                '21household',             '21level4',  '21populationdensity',\n",
      "               '21employment',          'Unnamed: 40',          'Unnamed: 41',\n",
      "                 'median2000',           'median2001',           'median2002',\n",
      "                 'median2003',           'median2004',           'median2005',\n",
      "                 'median2006',           'median2007',           'median2008',\n",
      "                 'median2009',           'median2010',           'median2011',\n",
      "                 'median2012',           'median2013',           'median2014',\n",
      "                 'median2015',           'median2016',           'median2017',\n",
      "                 'median2018',           'median2019',           'median2020',\n",
      "                 'median2021'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定数据文件的路径（当前目录中）\n",
    "file_path = 'finaldata.xlsx'\n",
    "\n",
    "# 加载Excel数据文件\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 打印所有列名以便检查\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f15337-554d-4754-a608-ac95ec1f52dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的数据已保存到 log_finaldata.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 指定数据文件的路径\n",
    "file_path = 'finaldata.xlsx'\n",
    "output_file_path = 'log_finaldata.xlsx'\n",
    "\n",
    "# 加载Excel数据文件\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 选择2000年至2020年的列，使用整数形式\n",
    "year_columns = list(range(2000, 2022))\n",
    "\n",
    "# 单独计算每列的自然对数，只替换零值\n",
    "log_data = data[year_columns].replace(0, np.nan).apply(np.log)\n",
    "\n",
    "# 重命名列名，添加\"Log\"前缀\n",
    "log_data.columns = ['Log ' + str(col) for col in year_columns]\n",
    "\n",
    "# 将计算后的自然对数数据插入到原始数据框中第34列之后\n",
    "result = pd.concat([data.iloc[:, :66], log_data, data.iloc[:, 66:]], axis=1)\n",
    "\n",
    "# 保存处理后的数据到新的Excel文件\n",
    "result.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"处理后的数据已保存到 {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f4566-b521-4dd7-901d-812e50a25172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
